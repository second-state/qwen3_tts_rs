name: CI

on:
  push:
  pull_request:

jobs:
  build:
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            name: Linux x86_64 (tch)
            backend: tch
            pip-extra-args: "--index-url https://download.pytorch.org/whl/cpu"
          - os: ubuntu-24.04-arm
            name: Linux ARM64 (tch)
            backend: tch
            pip-extra-args: ""
          - os: macos-latest
            name: macOS ARM64 (tch)
            backend: tch
            pip-extra-args: ""
          - os: macos-latest
            name: macOS ARM64 (MLX)
            backend: mlx
            pip-extra-args: ""

    runs-on: ${{ matrix.os }}
    name: Build (${{ matrix.name }})

    steps:
      - uses: actions/checkout@v4

      - name: Init MLX submodule
        if: matrix.backend == 'mlx'
        run: git submodule update --init --recursive

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo registry and build
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-${{ runner.arch }}-${{ matrix.backend }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-${{ runner.arch }}-${{ matrix.backend }}-cargo-

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install PyTorch
        if: matrix.backend == 'tch'
        run: pip install torch==2.7.1 ${{ matrix.pip-extra-args }}

      - name: Install HuggingFace tools
        run: pip install huggingface_hub transformers

      - name: Set library path (Linux)
        if: runner.os == 'Linux' && matrix.backend == 'tch'
        run: echo "LD_LIBRARY_PATH=$(python3 -c 'import torch; print(torch.__path__[0])')/lib:$LD_LIBRARY_PATH" >> "$GITHUB_ENV"

      - name: Set library path (macOS)
        if: runner.os == 'macOS' && matrix.backend == 'tch'
        run: echo "DYLD_LIBRARY_PATH=$(python3 -c 'import torch; print(torch.__path__[0])')/lib:$DYLD_LIBRARY_PATH" >> "$GITHUB_ENV"

      - name: Set linker rpath-link (ARM64 Linux)
        if: runner.arch == 'ARM64' && runner.os == 'Linux' && matrix.backend == 'tch'
        run: |
          TORCH_LIBS=$(python3 -c "import torch, pathlib; print(pathlib.Path(torch.__path__[0]).parent / 'torch.libs')")
          echo "RUSTFLAGS=-C link-arg=-Wl,-rpath-link,$TORCH_LIBS" >> "$GITHUB_ENV"

      - name: Build (tch)
        if: matrix.backend == 'tch'
        env:
          LIBTORCH_USE_PYTORCH: "1"
          LIBTORCH_BYPASS_VERSION_CHECK: "1"
        run: cargo build --release

      - name: Build (MLX)
        if: matrix.backend == 'mlx'
        run: cargo build --release --no-default-features --features mlx

      - name: Build examples
        if: matrix.backend == 'tch'
        env:
          LIBTORCH_USE_PYTORCH: "1"
          LIBTORCH_BYPASS_VERSION_CHECK: "1"
        run: cargo build --examples --release

      - name: Cache model weights
        uses: actions/cache@v4
        with:
          path: models/Qwen3-TTS-12Hz-0.6B-CustomVoice
          key: qwen3-tts-0.6b-customvoice-v1

      - name: Download model
        run: python3 -c "from huggingface_hub import snapshot_download; snapshot_download('Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice', local_dir='models/Qwen3-TTS-12Hz-0.6B-CustomVoice')"

      - name: Generate tokenizer.json
        run: |
          python3 -c "
          from transformers import AutoTokenizer
          tok = AutoTokenizer.from_pretrained('models/Qwen3-TTS-12Hz-0.6B-CustomVoice', trust_remote_code=True)
          tok.backend_tokenizer.save('models/Qwen3-TTS-12Hz-0.6B-CustomVoice/tokenizer.json')
          print('Saved tokenizer.json')
          "

      - name: Generate English audio
        run: |
          ./target/release/tts \
            models/Qwen3-TTS-12Hz-0.6B-CustomVoice \
            "Hello! This is a test of the Qwen3 TTS system running on CI." \
            Vivian \
            english
          mv output.wav vivian_english.wav

      - name: Generate Chinese audio
        run: |
          ./target/release/tts \
            models/Qwen3-TTS-12Hz-0.6B-CustomVoice \
            "你好！这是Qwen3语音合成系统的持续集成测试。" \
            Vivian \
            chinese
          mv output.wav vivian_chinese.wav

      - name: Generate Ryan reference audio
        run: |
          ./target/release/tts \
            models/Qwen3-TTS-12Hz-0.6B-CustomVoice \
            "The quick brown fox jumps over the lazy dog." \
            Ryan \
            english
          mv output.wav ryan_reference.wav

      - name: Cache Base model weights
        uses: actions/cache@v4
        with:
          path: models/Qwen3-TTS-12Hz-0.6B-Base
          key: qwen3-tts-0.6b-base-v1

      - name: Download Base model
        run: python3 -c "from huggingface_hub import snapshot_download; snapshot_download('Qwen/Qwen3-TTS-12Hz-0.6B-Base', local_dir='models/Qwen3-TTS-12Hz-0.6B-Base')"

      - name: Generate Base model tokenizer.json
        run: |
          python3 -c "
          from transformers import AutoTokenizer
          tok = AutoTokenizer.from_pretrained('models/Qwen3-TTS-12Hz-0.6B-Base', trust_remote_code=True)
          tok.backend_tokenizer.save('models/Qwen3-TTS-12Hz-0.6B-Base/tokenizer.json')
          print('Saved tokenizer.json')
          "

      - name: Voice clone from Ryan reference
        run: |
          ./target/release/voice_clone \
            models/Qwen3-TTS-12Hz-0.6B-Base \
            ryan_reference.wav \
            "This is a voice cloning test using Ryan as the reference speaker." \
            english
          mv output_voice_clone.wav output_ryan_clone.wav

      - name: Voice clone (ICL mode) from Ryan reference
        run: |
          ./target/release/voice_clone \
            models/Qwen3-TTS-12Hz-0.6B-Base \
            ryan_reference.wav \
            "This is a voice cloning test with in-context learning." \
            english \
            "The quick brown fox jumps over the lazy dog."
          mv output_voice_clone.wav output_ryan_clone_icl.wav

      - name: Cache 1.7B CustomVoice model weights
        uses: actions/cache@v4
        with:
          path: models/Qwen3-TTS-12Hz-1.7B-CustomVoice
          key: qwen3-tts-1.7b-customvoice-v1

      - name: Download 1.7B CustomVoice model
        run: python3 -c "from huggingface_hub import snapshot_download; snapshot_download('Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice', local_dir='models/Qwen3-TTS-12Hz-1.7B-CustomVoice')"

      - name: Generate 1.7B model tokenizer.json
        run: |
          python3 -c "
          from transformers import AutoTokenizer
          tok = AutoTokenizer.from_pretrained('models/Qwen3-TTS-12Hz-1.7B-CustomVoice', trust_remote_code=True)
          tok.backend_tokenizer.save('models/Qwen3-TTS-12Hz-1.7B-CustomVoice/tokenizer.json')
          print('Saved tokenizer.json')
          "

      - name: Generate urgent voice (1.7B with instruction)
        run: |
          ./target/release/tts \
            models/Qwen3-TTS-12Hz-1.7B-CustomVoice \
            "Breaking news! There has been a major development in the city center." \
            Vivian \
            english \
            "Speak in an urgent and excited voice"
          mv output.wav vivian_urgent_1.7b.wav

      - name: Generate happy voice (1.7B with instruction)
        run: |
          ./target/release/tts \
            models/Qwen3-TTS-12Hz-1.7B-CustomVoice \
            "I am so happy to announce that we have won the championship!" \
            Vivian \
            english \
            "Speak happily and joyfully"
          mv output.wav vivian_happy_1.7b.wav

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: qwen3-tts-${{ matrix.os }}-${{ runner.arch }}-${{ matrix.backend }}
          path: |
            target/release/tts
            target/release/voice_clone
            vivian_english.wav
            vivian_chinese.wav
            ryan_reference.wav
            output_ryan_clone.wav
            output_ryan_clone_icl.wav
            vivian_urgent_1.7b.wav
            vivian_happy_1.7b.wav
